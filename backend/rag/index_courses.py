import os
import shutil
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings

COURSES_DIR = "documents/cours/"
CHROMA_DIR = "chroma_db_cours"

# Supprimer l'ancien index
if os.path.exists(CHROMA_DIR):
    print("ğŸ—‘ï¸ Suppression de l'ancien index Chroma...")
    shutil.rmtree(CHROMA_DIR)

# Charger tous les .txt et .pdf
docs = []
files_loaded = 0
for filename in os.listdir(COURSES_DIR):
    path = os.path.join(COURSES_DIR, filename)
    if filename.endswith(".txt"):
        print(f"ğŸ“„ TXT : {filename}")
        docs += TextLoader(path).load()
        files_loaded += 1
    elif filename.endswith(".pdf"):
        print(f"ğŸ“„ PDF : {filename}")
        docs += PyPDFLoader(path).load()
        files_loaded += 1

if not docs:
    raise ValueError("âŒ Aucun document texte ou PDF trouvÃ©.")

print(f"ğŸ“š {files_loaded} fichier(s) chargÃ©(s), {len(docs)} document(s) extraits")

# DÃ©coupage
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
chunks = splitter.split_documents(docs)
print(f"ğŸ” {len(chunks)} chunk(s) gÃ©nÃ©rÃ©s pour l'indexation")

# Embeddings + Chroma
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
db = Chroma.from_documents(chunks, embedding=embeddings, persist_directory=CHROMA_DIR)
db.persist()

print("âœ… Index Chroma gÃ©nÃ©rÃ© avec PDF et TXT")
